{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導入函數庫\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyrenn as prn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0           1           2          3           4   \\\n",
      "Glucose   94.000000  194.000000  151.000000  96.000000  132.000000   \n",
      "940nm      0.269327    0.219982    0.206906   0.196199    0.206080   \n",
      "970nm      0.120466    0.098825    0.091965   0.088454    0.078868   \n",
      "1200nm     0.191357    0.173515    0.159846   0.157710    0.155542   \n",
      "1300nm     0.123018    0.112761    0.112143   0.106111    0.135156   \n",
      "940nm.1    0.012093    0.012662    0.015916   0.014630    0.030850   \n",
      "970nm.1    0.005398    0.005942    0.007077   0.006672    0.011711   \n",
      "1200nm.1   0.003886    0.004538    0.005099   0.005649    0.009522   \n",
      "1300nm.1   0.003506    0.002778    0.003027   0.003033    0.004838   \n",
      "\n",
      "                  5          6           7           8          9   \\\n",
      "Glucose   115.000000  90.000000  199.000000  197.000000  92.000000   \n",
      "940nm       0.204065   0.221712    0.195611    0.223127   0.310999   \n",
      "970nm       0.077419   0.084744    0.074838    0.085658   0.141554   \n",
      "1200nm      0.157323   0.163700    0.161899    0.174516   0.249891   \n",
      "1300nm      0.128930   0.157843    0.160449    0.138037   0.167243   \n",
      "940nm.1     0.014559   0.013157    0.013948    0.018711   0.021571   \n",
      "970nm.1     0.005518   0.005059    0.005355    0.007170   0.009674   \n",
      "1200nm.1    0.004994   0.004203    0.005245    0.006376   0.007155   \n",
      "1300nm.1    0.003787   0.003823    0.004774    0.004211   0.004294   \n",
      "\n",
      "             ...              75          76          77         78  \\\n",
      "Glucose      ...      137.000000  108.000000  104.000000  80.000000   \n",
      "940nm        ...        0.431021    0.485886    0.483940   0.796211   \n",
      "970nm        ...        0.160636    0.183119    0.182172   0.307221   \n",
      "1200nm       ...        0.242578    0.254944    0.261528   0.390608   \n",
      "1300nm       ...        0.190484    0.224582    0.199251   0.321289   \n",
      "940nm.1      ...        0.012123    0.011949    0.010285   0.004671   \n",
      "970nm.1      ...        0.004301    0.003250    0.003668   0.001647   \n",
      "1200nm.1     ...        0.002953    0.002517    0.002528   0.000961   \n",
      "1300nm.1     ...        0.001709    0.001023    0.001959   0.001129   \n",
      "\n",
      "                  79         80         81          82          83          84  \n",
      "Glucose   110.000000  92.000000  84.000000  145.000000  123.000000  100.000000  \n",
      "940nm       0.558832   0.554475   0.779122    0.526639    0.620883    0.618554  \n",
      "970nm       0.215363   0.214561   0.303112    0.203391    0.240248    0.239230  \n",
      "1200nm      0.278779   0.355415   0.418541    0.314627    0.369882    0.355057  \n",
      "1300nm      0.295307   0.266261   0.362157    0.280278    0.299142    0.302902  \n",
      "940nm.1     0.021709   0.014865   0.007647    0.018531    0.015897    0.011249  \n",
      "970nm.1     0.008005   0.005494   0.002773    0.006826    0.005911    0.003961  \n",
      "1200nm.1    0.003542   0.002531   0.001076    0.004142    0.001510    0.001799  \n",
      "1300nm.1    0.006255   0.003844   0.001387    0.004143    0.004740    0.002095  \n",
      "\n",
      "[9 rows x 85 columns]\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "#read All dataframe df from ANN_training_data.CSV\n",
    "file_name='ANN_training_data_AC_combination_1128.CSV'\n",
    "parameter_weights_name = 'Parameter_of_Weights'\n",
    "filepath='C:\\\\Users\\\\richard.weng\\\\Documents\\\\Python Scripts\\\\python_projects\\\\(1) NIVG Project\\\\ANN\\\\'\n",
    "file_data = filepath+file_name\n",
    "df=pd.read_csv(file_data)\n",
    "#移除first column of tester label\n",
    "df = df.iloc[:,1:]\n",
    "print (df.T)\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0         1         2         3         4         5   \\\n",
      "940nm     0.269327  0.219982  0.206906  0.196199  0.206080  0.204065   \n",
      "970nm     0.120466  0.098825  0.091965  0.088454  0.078868  0.077419   \n",
      "1200nm    0.191357  0.173515  0.159846  0.157710  0.155542  0.157323   \n",
      "1300nm    0.123018  0.112761  0.112143  0.106111  0.135156  0.128930   \n",
      "940nm.1   0.012093  0.012662  0.015916  0.014630  0.030850  0.014559   \n",
      "970nm.1   0.005398  0.005942  0.007077  0.006672  0.011711  0.005518   \n",
      "1200nm.1  0.003886  0.004538  0.005099  0.005649  0.009522  0.004994   \n",
      "1300nm.1  0.003506  0.002778  0.003027  0.003033  0.004838  0.003787   \n",
      "\n",
      "                6         7         8         9     ...           75  \\\n",
      "940nm     0.221712  0.195611  0.223127  0.310999    ...     0.431021   \n",
      "970nm     0.084744  0.074838  0.085658  0.141554    ...     0.160636   \n",
      "1200nm    0.163700  0.161899  0.174516  0.249891    ...     0.242578   \n",
      "1300nm    0.157843  0.160449  0.138037  0.167243    ...     0.190484   \n",
      "940nm.1   0.013157  0.013948  0.018711  0.021571    ...     0.012123   \n",
      "970nm.1   0.005059  0.005355  0.007170  0.009674    ...     0.004301   \n",
      "1200nm.1  0.004203  0.005245  0.006376  0.007155    ...     0.002953   \n",
      "1300nm.1  0.003823  0.004774  0.004211  0.004294    ...     0.001709   \n",
      "\n",
      "                76        77        78        79        80        81  \\\n",
      "940nm     0.485886  0.483940  0.796211  0.558832  0.554475  0.779122   \n",
      "970nm     0.183119  0.182172  0.307221  0.215363  0.214561  0.303112   \n",
      "1200nm    0.254944  0.261528  0.390608  0.278779  0.355415  0.418541   \n",
      "1300nm    0.224582  0.199251  0.321289  0.295307  0.266261  0.362157   \n",
      "940nm.1   0.011949  0.010285  0.004671  0.021709  0.014865  0.007647   \n",
      "970nm.1   0.003250  0.003668  0.001647  0.008005  0.005494  0.002773   \n",
      "1200nm.1  0.002517  0.002528  0.000961  0.003542  0.002531  0.001076   \n",
      "1300nm.1  0.001023  0.001959  0.001129  0.006255  0.003844  0.001387   \n",
      "\n",
      "                82        83        84  \n",
      "940nm     0.526639  0.620883  0.618554  \n",
      "970nm     0.203391  0.240248  0.239230  \n",
      "1200nm    0.314627  0.369882  0.355057  \n",
      "1300nm    0.280278  0.299142  0.302902  \n",
      "940nm.1   0.018531  0.015897  0.011249  \n",
      "970nm.1   0.006826  0.005911  0.003961  \n",
      "1200nm.1  0.004142  0.001510  0.001799  \n",
      "1300nm.1  0.004143  0.004740  0.002095  \n",
      "\n",
      "[8 rows x 85 columns]\n",
      "(8, 85)\n",
      "           0      1      2     3      4      5     6      7      8     9   \\\n",
      "Glucose  94.0  194.0  151.0  96.0  132.0  115.0  90.0  199.0  197.0  92.0   \n",
      "\n",
      "         ...       75     76     77    78     79    80    81     82     83  \\\n",
      "Glucose  ...    137.0  108.0  104.0  80.0  110.0  92.0  84.0  145.0  123.0   \n",
      "\n",
      "            84  \n",
      "Glucose  100.0  \n",
      "\n",
      "[1 rows x 85 columns]\n",
      "(1, 85)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14333333, 0.3075    , 0.43      , 0.14333333, 0.32833333,\n",
       "        0.17333333, 0.16      , 0.14      , 0.13666667, 0.22916667,\n",
       "        0.305     , 0.15666667, 0.15666667, 0.22      , 0.18666667,\n",
       "        0.145     , 0.18333333, 0.32333333, 0.21      , 0.13666667,\n",
       "        0.17833333, 0.265     , 0.155     , 0.2175    , 0.18833333,\n",
       "        0.18166667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = df.T.iloc[1:9,0:85]\n",
    "print(P)\n",
    "print(P.shape)\n",
    "Y = df.T.iloc[0:1,0:85]\n",
    "print(Y)\n",
    "print(Y.shape)\n",
    "\n",
    "#轉成2d array\n",
    "P = np.array(P)\n",
    "Y = np.array(Y)\n",
    "print(type(P))\n",
    "print(type(Y))\n",
    "\n",
    "# 假設70%訓練，30%要驗證 (TrainingData and TestingData)\n",
    "x_train, x_test, y_train, y_test = train_test_split(P.T,Y.T,test_size=0.3,random_state=30)\n",
    "x_train = x_train.T/np.amax(x_train.T, axis=0)\n",
    "x_test = x_test.T/np.amax(x_test.T, axis=0)\n",
    "y_train = y_train.T/600\n",
    "y_test = y_test.T/600\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 error: 42.97612204094295\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'range' object has no attribute 'reverse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-026dc2cbae30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0mbp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetStruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiv_fun_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#初始化网络信息\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#初始化训练网络的类\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeaksSamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#产生测试数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[0mXX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-026dc2cbae30>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_struct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-026dc2cbae30>\u001b[0m in \u001b[0;36mlm\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;31m#2) step 2:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparDeriv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mje\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjjje\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-026dc2cbae30>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m                                             self.net_struct.active_fun_list[layer_num - 2])\n\u001b[0;32m    103\u001b[0m         \u001b[0mlayer_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_num\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mlayer_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mcurr_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_struct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'range' object has no attribute 'reverse'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import exp, pow\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import copy\n",
    "from scipy.linalg import norm, pinv\n",
    "class Layer:\n",
    "    def __init__(self,w, b, neure_number, transfer_function, layer_index):\n",
    "        self.transfer_function = transfer_function\n",
    "        self.neure_number = neure_number\n",
    "        self.layer_index = layer_index\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "class NetStruct:\n",
    "    def __init__(self, x, y, hidden_layers, activ_fun_list, performance_function = 'mse'):\n",
    "        if len(hidden_layers) == len(activ_fun_list):\n",
    "            activ_fun_list.append('line')\n",
    "        self.active_fun_list = activ_fun_list\n",
    "        self.performance_function = performance_function\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        if(x.shape[1] != y.shape[1]):\n",
    "            print ('The dimension of x and y are not same.')\n",
    "            sys.exit()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        input_eles = self.x.shape[0]\n",
    "        output_eles = self.y.shape[0]\n",
    "        tmp = []\n",
    "        tmp.append(input_eles)\n",
    "        tmp.extend(hidden_layers)\n",
    "        tmp.append(output_eles)\n",
    "        self.hidden_layers = np.array(tmp)\n",
    "        self.layer_num = len(self.hidden_layers)\n",
    "        self.layers = []\n",
    "        for i in range(0, len(self.hidden_layers)):\n",
    "            \n",
    "            if i == 0:\n",
    "                self.layers.append(Layer([],[],\\\n",
    "                                        self.hidden_layers[i], 'none', i)) \n",
    "                continue\n",
    "            f = self.hidden_layers[i - 1]\n",
    "            s = self.hidden_layers[i] \n",
    "            self.layers.append(Layer(np.random.randn(s, f),np.random.randn(s, 1),\\\n",
    "                                        self.hidden_layers[i], activ_fun_list[i-1], i)) \n",
    "    \n",
    "class Train:\n",
    "    def __init__(self, net_struct, mu = 1e-3, beta = 10, iteration = 100, tol = 0.1):\n",
    "        self.net_struct = net_struct\n",
    "        self.mu = mu\n",
    "        self.beta = beta\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "    def train(self, method = 'lm'):\n",
    "        if(method == 'lm'):\n",
    "            self.lm()\n",
    "    def sim(self, x):\n",
    "        self.net_struct.x = x\n",
    "        self.forward()\n",
    "        layer_num = len(self.net_struct.layers)\n",
    "        predict = self.net_struct.layers[layer_num - 1].output_val\n",
    "        return predict\n",
    "    def actFun(self, z, activ_type = 'sigm'):\n",
    "        if activ_type == 'sigm':            \n",
    "            f = 1.0 / (1.0 + np.exp(-z))\n",
    "        elif activ_type == 'tanh':\n",
    "            f = (np.exp(z) + np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "        elif activ_type == 'radb':\n",
    "            f = np.exp(-z * z)\n",
    "        elif activ_type == 'line':\n",
    "            f = z\n",
    "        return f\n",
    "    def actFunGrad(self, z, activ_type = 'sigm'):\n",
    "        if activ_type == 'sigm':\n",
    "            grad = self.actFun(z, activ_type) * (1.0 - self.actFun(z, activ_type))\n",
    "        elif activ_type == 'tanh':\n",
    "            grad = 1.0 - self.actFun(z, activ_type) * self.actFun(z, activ_type)\n",
    "        elif activ_type == 'radb':\n",
    "            grad = -2.0 * z * self.actFun(z, activ_type)\n",
    "        elif activ_type == 'line':\n",
    "            m = z.shape[0]\n",
    "            n = z.shape[1]\n",
    "            grad = np.ones((m, n))\n",
    "        return grad\n",
    "    def forward(self):\n",
    "        layer_num = len(self.net_struct.layers)\n",
    "        for i in range(0, layer_num):\n",
    "            if i == 0:\n",
    "                curr_layer = self.net_struct.layers[i]\n",
    "                curr_layer.input_val = self.net_struct.x\n",
    "                curr_layer.output_val = self.net_struct.x\n",
    "                continue\n",
    "            before_layer = self.net_struct.layers[i - 1]\n",
    "            curr_layer = self.net_struct.layers[i]\n",
    "            curr_layer.input_val = curr_layer.w.dot(before_layer.output_val) + curr_layer.b\n",
    "            curr_layer.output_val = self.actFun(curr_layer.input_val, \n",
    "                                                self.net_struct.active_fun_list[i - 1])\n",
    "    def backward(self):\n",
    "        layer_num = len(self.net_struct.layers)\n",
    "        last_layer = self.net_struct.layers[layer_num - 1]\n",
    "        last_layer.error = -self.actFunGrad(last_layer.input_val,\n",
    "                                            self.net_struct.active_fun_list[layer_num - 2])\n",
    "        layer_index = range(1, layer_num - 1)\n",
    "        layer_index.reverse()\n",
    "        for i in layer_index:\n",
    "            curr_layer = self.net_struct.layers[i]\n",
    "            curr_layer.error = (last_layer.w.transpose().dot(last_layer.error)) \\\n",
    "                      * self.actFunGrad(curr_layer.input_val,self.net_struct.active_fun_list[i - 1])\n",
    "            last_layer = curr_layer\n",
    "    def parDeriv(self):\n",
    "        layer_num = len(self.net_struct.layers)\n",
    "        for i in range(1, layer_num):\n",
    "            befor_layer = self.net_struct.layers[i - 1]\n",
    "            befor_input_val = befor_layer.output_val.transpose()\n",
    "            curr_layer = self.net_struct.layers[i]\n",
    "            curr_error = curr_layer.error\n",
    "            curr_error = curr_error.reshape(curr_error.shape[0]*curr_error.shape[1], 1, order='F')\n",
    "            row =  curr_error.shape[0]\n",
    "            col = befor_input_val.shape[1]\n",
    "            a = np.zeros((row, col))\n",
    "            num = befor_input_val.shape[0]\n",
    "            neure_number = curr_layer.neure_number\n",
    "            for i in range(0, num):\n",
    "                a[neure_number*i:neure_number*i + neure_number,:] = \\\n",
    "                 np.repeat([befor_input_val[i,:]],neure_number,axis = 0)\n",
    "            tmp_w_par_deriv = curr_error * a\n",
    "            curr_layer.w_par_deriv = np.zeros((num, befor_layer.neure_number * curr_layer.neure_number))\n",
    "            for i in range(0, num):\n",
    "                tmp = tmp_w_par_deriv[neure_number*i:neure_number*i + neure_number,:]\n",
    "                tmp = tmp.reshape(tmp.shape[0] * tmp.shape[1], order='C')\n",
    "                curr_layer.w_par_deriv[i, :] = tmp\n",
    "            curr_layer.b_par_deriv = curr_layer.error.transpose()\n",
    "    def jacobian(self):\n",
    "        layers = self.net_struct.hidden_layers\n",
    "        row = self.net_struct.x.shape[1]\n",
    "        col = 0\n",
    "        for i in range(0, len(layers) - 1):\n",
    "            col = col + layers[i] * layers[i + 1] + layers[i + 1]\n",
    "        j = np.zeros((row, col))\n",
    "        layer_num = len(self.net_struct.layers)\n",
    "        index = 0\n",
    "        for i in range(1, layer_num):\n",
    "            curr_layer = self.net_struct.layers[i]\n",
    "            w_col = curr_layer.w_par_deriv.shape[1]\n",
    "            b_col = curr_layer.b_par_deriv.shape[1]\n",
    "            j[:, index : index + w_col] = curr_layer.w_par_deriv\n",
    "            index = index + w_col\n",
    "            j[:, index : index + b_col] = curr_layer.b_par_deriv\n",
    "            index = index + b_col\n",
    "        return j\n",
    "    def gradCheck(self):\n",
    "        W1 = self.net_struct.layers[1].w\n",
    "        b1 = self.net_struct.layers[1].b\n",
    "        n = self.net_struct.layers[1].neure_number\n",
    "        W2 = self.net_struct.layers[2].w\n",
    "        b2 = self.net_struct.layers[2].b\n",
    "        x = self.net_struct.x\n",
    "        p = []\n",
    "        p.extend(W1.reshape(1,W1.shape[0]*W1.shape[1],order = 'C')[0])\n",
    "        p.extend(b1.reshape(1,b1.shape[0]*b1.shape[1],order = 'C')[0])\n",
    "        p.extend(W2.reshape(1,W2.shape[0]*W2.shape[1],order = 'C')[0])\n",
    "        p.extend(b2.reshape(1,b2.shape[0]*b2.shape[1],order = 'C')[0])\n",
    "        old_p = p\n",
    "        jac = []\n",
    "        for i in range(0, x.shape[1]):\n",
    "            xi = np.array([x[:,i]])\n",
    "            xi = xi.transpose()\n",
    "            ji = []\n",
    "            for j in range(0, len(p)):\n",
    "                W1 = np.array(p[0:2*n]).reshape(n,2,order='C')\n",
    "                b1 = np.array(p[2*n:2*n+n]).reshape(n,1,order='C')\n",
    "                W2 = np.array(p[3*n:4*n]).reshape(1,n,order='C')\n",
    "                b2 = np.array(p[4*n:4*n+1]).reshape(1,1,order='C')\n",
    "                \n",
    "                z2 = W1.dot(xi) + b1\n",
    "                a2 = self.actFun(z2)\n",
    "                z3 = W2.dot(a2) + b2\n",
    "                h1 = self.actFun(z3)\n",
    "                p[j] = p[j] + 0.00001\n",
    "                W1 = np.array(p[0:2*n]).reshape(n,2,order='C')\n",
    "                b1 = np.array(p[2*n:2*n+n]).reshape(n,1,order='C')\n",
    "                W2 = np.array(p[3*n:4*n]).reshape(1,n,order='C')\n",
    "                b2 = np.array(p[4*n:4*n+1]).reshape(1,1,order='C')\n",
    "                \n",
    "                z2 = W1.dot(xi) + b1\n",
    "                a2 = self.actFun(z2)\n",
    "                z3 = W2.dot(a2) + b2\n",
    "                h = self.actFun(z3)\n",
    "                g = (h[0][0]-h1[0][0])/0.00001\n",
    "                ji.append(g)\n",
    "            jac.append(ji)\n",
    "            p = old_p\n",
    "        return jac\n",
    "    def jjje(self):\n",
    "        layer_number = self.net_struct.layer_num\n",
    "        e = self.net_struct.y - \\\n",
    "          self.net_struct.layers[layer_number - 1].output_val\n",
    "        e = e.transpose()\n",
    "        j = self.jacobian()\n",
    "        #check gradient\n",
    "        #j1 = -np.array(self.gradCheck())\n",
    "        #jk = j.reshape(1,j.shape[0]*j.shape[1])\n",
    "        #jk1 = j1.reshape(1,j1.shape[0]*j1.shape[1])\n",
    "        #plt.plot(jk[0])\n",
    "        #plt.plot(jk1[0],'.')\n",
    "        #plt.show()\n",
    "        jj = j.transpose().dot(j)\n",
    "        je = -j.transpose().dot(e)\n",
    "        return[jj, je]\n",
    "    def lm(self):\n",
    "        mu = self.mu\n",
    "        beta = self.beta\n",
    "        iteration = self.iteration\n",
    "        tol = self.tol\n",
    "        y = self.net_struct.y\n",
    "        self.forward()\n",
    "        pred =  self.net_struct.layers[self.net_struct.layer_num - 1].output_val\n",
    "        pref = self.perfermance(y, pred)\n",
    "        for i in range(0, iteration):\n",
    "            print ('iter:',i, 'error:', pref)\n",
    "            #1) step 1: \n",
    "            if(pref < tol):\n",
    "                break\n",
    "            #2) step 2:\n",
    "            self.backward()\n",
    "            self.parDeriv()\n",
    "            [jj, je] = self.jjje()\n",
    "            while(1):\n",
    "                #3) step 3: \n",
    "                A = jj + mu * np.diag(np.ones(jj.shape[0]))\n",
    "                delta_w_b = pinv(A).dot(je)\n",
    "                #4) step 4:\n",
    "                old_net_struct = copy.deepcopy(self.net_struct)\n",
    "                self.updataNetStruct(delta_w_b)\n",
    "                self.forward()\n",
    "                pred1 =  self.net_struct.layers[self.net_struct.layer_num - 1].output_val\n",
    "                pref1 = self.perfermance(y, pred1)\n",
    "                if (pref1 < pref):\n",
    "                    mu = mu / beta\n",
    "                    pref = pref1\n",
    "                    break\n",
    "                mu = mu * beta\n",
    "                self.net_struct = copy.deepcopy(old_net_struct)\n",
    "    def updataNetStruct(self, delta_w_b):\n",
    "        layer_number = self.net_struct.layer_num\n",
    "        index = 0\n",
    "        for i in range(1, layer_number):\n",
    "            before_layer = self.net_struct.layers[i - 1]\n",
    "            curr_layer = self.net_struct.layers[i]\n",
    "            w_num = before_layer.neure_number * curr_layer.neure_number\n",
    "            b_num = curr_layer.neure_number\n",
    "            w = delta_w_b[index : index + w_num]\n",
    "            w = w.reshape(curr_layer.neure_number, before_layer.neure_number, order='C')\n",
    "            index = index + w_num\n",
    "            b = delta_w_b[index : index + b_num]\n",
    "            index = index + b_num\n",
    "            curr_layer.w += w\n",
    "            curr_layer.b += b\n",
    "    def perfermance(self, y, pred):\n",
    "        error = y - pred\n",
    "        return norm(error) / len(y)  \n",
    "    def plotSamples(self, n = 40):\n",
    "        x = np.array([np.linspace(0, 3, n)])\n",
    "        x = x.repeat(n, axis = 0)\n",
    "        y = x.transpose()\n",
    "        z = np.zeros((n, n))\n",
    "        for i in range(0, x.shape[0]):\n",
    "            for j in range(0, x.shape[1]):\n",
    "                z[i][j] = self.sampleFun(x[i][j], y[i][j])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        surf = ax.plot_surface(x, y, z, cmap='autumn', cstride=2, rstride=2)\n",
    "        ax.set_xlabel(\"X-Label\")\n",
    "        ax.set_ylabel(\"Y-Label\")\n",
    "        ax.set_zlabel(\"Z-Label\")\n",
    "        plt.show()\n",
    "def sinSamples(n):\n",
    "        x = np.array([np.linspace(-0.5, 0.5, n)])\n",
    "        #x = x.repeat(n, axis = 0)\n",
    "        y = x + 0.2\n",
    "        z = np.zeros((n, 1))\n",
    "        for i in range(0, x.shape[1]):\n",
    "            z[i] = np.sin(x[0][i] * y[0][i])\n",
    "        X = np.zeros((n, 2))\n",
    "        n = 0\n",
    "        for xi, yi in zip(x.transpose(), y.transpose()):\n",
    "            X[n][0] = xi\n",
    "            X[n][1] = yi\n",
    "            n = n + 1\n",
    "        return X,z\n",
    "def peaksSamples(n):\n",
    "    x = np.array([np.linspace(-3, 3, n)])\n",
    "    x = x.repeat(n, axis = 0)\n",
    "    y = x.transpose()\n",
    "    z = np.zeros((n, n))\n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            z[i][j] = sampleFun(x[i][j], y[i][j])\n",
    "    X = np.zeros((n*n, 2))\n",
    "    x_list = x.reshape(n*n,1 )\n",
    "    y_list = y.reshape(n*n,1)\n",
    "    z_list = z.reshape(n*n,1)\n",
    "    n = 0\n",
    "    for xi, yi in zip(x_list, y_list):\n",
    "        X[n][0] = xi\n",
    "        X[n][1] = yi\n",
    "        n = n + 1\n",
    "    \n",
    "    return X,z_list.transpose()\n",
    "def sampleFun(x, y):\n",
    "    z =  3*pow((1-x),2) * exp(-(pow(x,2)) - pow((y+1),2)) \\\n",
    "   - 10*(x/5 - pow(x, 3) - pow(y, 5)) * exp(-pow(x, 2) - pow(y, 2)) \\\n",
    "   - 1/3*exp(-pow((x+1), 2) - pow(y, 2)) \n",
    "    return z\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    hidden_layers = [10,10] #设置网络层数，共两层，每层10个神经元\n",
    "    activ_fun_list = ['sigm','sigm']#设置隐层的激活函数类型，可以设置为tanh,radb，tanh,line类型，如果不显式的设置最后一层为line \n",
    " \n",
    "    [X, z] = peaksSamples(20) #产生训练数据点\n",
    "    X = X.transpose()\n",
    "    bp = NetStruct(X, z, hidden_layers, activ_fun_list) #初始化网络信息\n",
    "    tr = Train(bp) #初始化训练网络的类\n",
    "    tr.train() #训练\n",
    "    [XX, z0] = peaksSamples(40) #产生测试数据\n",
    "    XX = XX.transpose()\n",
    "    z1 = tr.sim(XX) #用训练好的神经网络预测数据，z1为预测结果\n",
    "    \n",
    "    fig  = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(z0[0]) #真值\n",
    "    ax.plot(z1[0],'r.') #预测值\n",
    "    plt.legend((r'real data', r'predict data'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
